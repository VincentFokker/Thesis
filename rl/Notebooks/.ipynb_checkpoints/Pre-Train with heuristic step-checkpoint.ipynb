{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rl\\\\helpers\\\\start_states.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-038260b8b2a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0menv_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menvironments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_binary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\drive\\git\\rl\\rl\\environments\\AbstractConveyor1.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m#load set of predefined start_states generated with the heuristic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'helpers'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'start_states.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rl\\\\helpers\\\\start_states.json'"
     ]
    }
   ],
   "source": [
    "import rl.environments\n",
    "import yaml\n",
    "from stable_baselines import PPO2\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "import rl.helpers\n",
    "import gym\n",
    "from stable_baselines.gail import generate_expert_traj\n",
    "from stable_baselines.gail import ExpertDataset\n",
    "from stable_baselines import PPO2\n",
    "import pathlib\n",
    "from os.path import join\n",
    "from stable_baselines.common import make_vec_env\n",
    "from stable_baselines.common.callbacks import EvalCallback\n",
    "\n",
    "path = 'D:/Drive/git/RL/'\n",
    "env_name = 'AbstractConveyor1'\n",
    "subdir = '20210102_1000'\n",
    "\n",
    "config_path = join(path, 'rl', 'config','{}.yml'.format(env_name))\n",
    "with open(config_path, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "env_obj = getattr(rl.environments, env_name)\n",
    "env = env_obj(config)\n",
    "\n",
    "def decode_binary(binary_array):\n",
    "    return [int(\"\".join([str(n) for n in [int(l) for l in list(binary_array[i-2:i])]]),2) for i in range(2,len(binary_array)+2,2)]\n",
    "\n",
    "def decode_action(order_type, goal):\n",
    "    return (order_type-1 )* env.amount_of_gtps + goal\n",
    "\n",
    "def dummy_expert(obs):\n",
    "    \"\"\"\n",
    "    Based on observation , heuristic determines the policy  ( can only take observation [4, 15, 16, 17, 18])\n",
    "\n",
    "    :param _obs: (np.ndarray) Current observation\n",
    "    :return: (np.ndarray) action taken by the expert\n",
    "    \"\"\"\n",
    "    threshold = 15\n",
    "    \n",
    "    demands = decode_binary(obs[:2*env.amount_of_gtps*env.in_que_observed])\n",
    "    queue_demands = [demands[i*env.in_que_observed: env.in_que_observed +i*env.in_que_observed] for i in range(env.amount_of_gtps)]\n",
    "    W_rpt = obs[2*env.amount_of_gtps*env.in_que_observed:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps]\n",
    "    max_time_w = 6 if env.amount_of_outputs==1 else 30 if env.amount_of_outputs==2 else 60\n",
    "    W_rpt = W_rpt * max_time_w\n",
    "    \n",
    "    \n",
    "    Q_rpt = obs[2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*2]\n",
    "    max_time_q = max_time_w*env.gtp_buffer_length\n",
    "    Q_rpt = Q_rpt * max_time_q\n",
    "    \n",
    "    P_rpt = obs[2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*2:2*env.amount_of_gtps*env.in_que_observed+env.amount_of_gtps*3]\n",
    "    P_rpt = P_rpt*env.pipeline_length\n",
    "    \n",
    "    in_pipe = obs[2 * env.amount_of_gtps * env.in_que_observed + env.amount_of_gtps * 3:2 * env.amount_of_gtps * env.in_que_observed + env.amount_of_gtps * 4]\n",
    "    #in_pipe = obs[-env.amount_of_gtps:]\n",
    "    in_pipe = in_pipe*env.pipeline_length\n",
    "    in_pipe = in_pipe.astype(int)\n",
    "    \n",
    "    actions_list = []\n",
    "    for workstation in range(env.amount_of_gtps)[::-1]:\n",
    "        total_rpt = W_rpt[workstation] + Q_rpt[workstation] + P_rpt[workstation]\n",
    "        total_pipe = env.pipeline_length + env.gtp_buffer_length + workstation * 4 + 2\n",
    "        \n",
    "        if total_rpt - total_pipe < threshold:\n",
    "            try:\n",
    "                current_demand = queue_demands[workstation][in_pipe[workstation]]\n",
    "                actions_list.append((current_demand, workstation + 1))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    try:\n",
    "        order_type, goal = actions_list[0]\n",
    "        actions_list = actions_list[1:]\n",
    "\n",
    "    except:\n",
    "        order_type, goal = 0, 0\n",
    "    \n",
    "    if order_type ==0 and goal == 0:\n",
    "        action = 0\n",
    "        \n",
    "    else:\n",
    "        action = decode_action(order_type, goal)\n",
    "\n",
    "    \n",
    "    return action\n",
    "\n",
    "## Generate Data based on heuristic for pre-training\n",
    "# Data will be saved in a numpy archive named `heuristic_expert.npz`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('D:/Drive/git/RL/Notebooks')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pathlib.Path().absolute()\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{0: 0, 1: 0, 2: 0, 3: 0, 4: 0}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(dummy_expert(env.make_observation()))\n",
    "env.step(dummy_expert(env.make_observation()))\n",
    "print(env.idle_times_operator)\n",
    "env.render_plt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions (71552, 1)1483, R: 0.0000\n",
      "obs (71552, 28)\n",
      "rewards (71552,)\n",
      "episode_returns (50,)\n",
      "episode_starts (71552,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'actions': array([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]), 'obs': array([[1., 0., 1., ..., 6., 2., 1.],\n",
       "        [1., 0., 1., ..., 6., 1., 1.],\n",
       "        [1., 0., 1., ..., 6., 1., 1.],\n",
       "        ...,\n",
       "        [0., 1., 1., ..., 6., 0., 1.],\n",
       "        [0., 1., 1., ..., 6., 0., 1.],\n",
       "        [0., 1., 1., ..., 6., 0., 1.]]), 'rewards': array([10.,  0.,  0., ...,  0.,  0.,  0.]), 'episode_returns': array([ 365.,  535.,  520.,  810.,  525.,  420.,  285., -130.,  425.,\n",
       "         650.,  370.,  520.,  520.,  965.,  430.,  365.,  590.,  570.,\n",
       "         405.,  620.,  475.,  530.,  520.,  470.,  535.,  840.,  370.,\n",
       "         530.,  580.,  330.,  490.,   35.,  465.,  250.,  515.,  365.,\n",
       "         635.,  240.,  515.,  410.,  555.,  795.,  335.,  620.,  675.,\n",
       "         630.,  720.,  445.,  650.,  485.]), 'episode_starts': array([ True, False, False, ..., False, False, False])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Generate Data based on heuristic for pre-training\n",
    "# Data will be saved in a numpy archive named `heuristic_expert.npz`\n",
    "env.reset()\n",
    "generate_expert_traj(dummy_expert, 'heuristic_expert', env, n_episodes=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th_new-venv",
   "language": "python",
   "name": "th_new-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
